[
    {"Rank": 0, "Method": "Random", "Attribution Method Type": "Other", "Model": "Pythia-1b", "Model Size": "1B", "avg": 45.34, "sciq": 0.689, "arc_easy": 0.431, "arc_challenge": 0.244, "logiqa": 0.275, "boolq": 0.520, "hellaswag": 0.407, "piqa": 0.690, "winogrande": 0.535, "openbookqa": 0.290, "Paper/Code/Contact Link": ""},
    {"Rank": 0, "Method": "BM25", "Attribution Method Type": "Lexical", "Model": "Pythia-1b", "Model Size": "1B", "avg": 45.72, "sciq": 0.692, "arc_easy": 0.439, "arc_challenge": 0.239, "logiqa": 0.260, "boolq": 0.556, "hellaswag": 0.406, "piqa": 0.696, "winogrande": 0.531, "openbookqa": 0.296, "Paper/Code/Contact Link": ""},
    {"Rank": 0, "Method": "Grad Sim", "Attribution Method Type": "Gradient", "Model": "Pythia-1b", "Model Size": "1B", "avg": 45.98, "sciq": 0.689, "arc_easy": 0.440, "arc_challenge": 0.240, "logiqa": 0.272, "boolq": 0.556, "hellaswag": 0.406, "piqa": 0.690, "winogrande": 0.537, "openbookqa": 0.308, "Paper/Code/Contact Link": ""},
    {"Rank": 0, "Method": "Rep Sim", "Attribution Method Type": "Similarity", "Model": "Pythia-1b", "Model Size": "1B", "avg": 46.00, "sciq": 0.691, "arc_easy": 0.441, "arc_challenge": 0.237, "logiqa": 0.275, "boolq": 0.561, "hellaswag": 0.409, "piqa": 0.695, "winogrande": 0.537, "openbookqa": 0.294, "Paper/Code/Contact Link": ""},
    {"Rank": 0, "Method": "Mates", "Attribution Method Type": "Modeling", "Model": "Pythia-1b", "Model Size": "1B", "avg": 45.76, "sciq": 0.685, "arc_easy": 0.441, "arc_challenge": 0.241, "logiqa": 0.269, "boolq": 0.563, "hellaswag": 0.408, "piqa": 0.696, "winogrande": 0.523, "openbookqa": 0.292, "Paper/Code/Contact Link": ""},
    {"Rank": 0, "Method": "Edu", "Attribution Method Type": "Other", "Model": "Pythia-1b", "Model Size": "1B", "avg": 45.83, "sciq": 0.688, "arc_easy": 0.452, "arc_challenge": 0.240, "logiqa": 0.264, "boolq": 0.571, "hellaswag": 0.409, "piqa": 0.689, "winogrande": 0.520, "openbookqa": 0.292, "Paper/Code/Contact Link": ""}
]